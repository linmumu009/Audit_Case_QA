from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.runtime import get_runtime
from langchain_openai import ChatOpenAI
from elasticsearch import Elasticsearch
from openai import OpenAI
from pathlib import Path
from types import SimpleNamespace

from es_tools.tools import ESVectorSearchTool

# ESé…ç½®é¡¹ï¼Œåœ°å€ã€æ¥å£ã€ä»“åº“
ES_HOST = "http://localhost:9200"
es = Elasticsearch(f"{ES_HOST}")
index_name = "audit_2025_cases"

def load_llm_api_key():
    """ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½APIå¯†é’¥"""
    config_path = Path("config/qwen_long_api_key.txt")
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            api_key = f.read().strip()
        if not api_key:
            raise ValueError("APIå¯†é’¥æ–‡ä»¶ä¸ºç©º")
        return api_key
    except FileNotFoundError:
        raise FileNotFoundError(f"APIå¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    except Exception as e:
        raise Exception(f"è¯»å–APIå¯†é’¥å¤±è´¥: {e}")

api_key = load_llm_api_key()
# def load_embed_api_key():
#     """ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½APIå¯†é’¥"""
#     config_path = Path("config/guiji.txt")
#     try:
#         with open(config_path, 'r', encoding='utf-8') as f:
#             api_key = f.read().strip()
#         if not api_key:
#             raise ValueError("APIå¯†é’¥æ–‡ä»¶ä¸ºç©º")
#         return api_key
#     except FileNotFoundError:
#         raise FileNotFoundError(f"APIå¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
#     except Exception as e:
#         raise Exception(f"è¯»å–APIå¯†é’¥å¤±è´¥: {e}")
        
# em_api_key = load_embed_api_key()
# OpenAIçš„embeddingæ¥å£
client = OpenAI(
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=api_key,
)

# æ–‡æœ¬è½¬å‘é‡
def text2vec(case: str) -> dict:
    completion = client.embeddings.create(
        model="text-embedding-v3", input=case, dimensions=1024
    )
    return completion.data[0].embedding

# å¤§æ¨¡å‹æ¥å£
llm = ChatOpenAI(
    model="qwen-plus",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=api_key,
)

# å›ºåŒ–ä¿¡æ¯
class Ctx(TypedDict):
    """
    ä¸æ›´æ”¹çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®¢æˆ·ä¿¡æ¯ã€æ£€ç´¢topkã€æ£€ç´¢é˜ˆå€¼
    """

    user_name: str
    user_province: str = ""
    user_city: str = ""
    user_district: str = ""
    user_subcompany: str = ""
    topk: int = 3
    threshold: float = 0.0


# çŠ¶æ€ä¿¡æ¯
class State(TypedDict):
    """
    ä¿æŒæ›´æ–°çš„çŠ¶æ€å®šä¹‰
    """

    messages: Annotated[list, add_messages]
    memory: list
    query: str
    reject: str
    ask_further: str
    query_rewrite: str
    cases: list
    response: str


# æ‹’ç­”åˆ¤æ–­
def reject(state: State):
    """
    åˆ¤æ–­æ˜¯å¦æ‹’ç»å›ç­”ï¼Œæ›´æ–°åœ¨çŠ¶æ€çš„"reject"å­—æ®µ
    1. è¿”å›â€œå›ç­”â€ï¼šç›®æ ‡æ˜ç¡®ä¸”ä¸è¿è§„
    2. è¿”å›â€œæ‹’ç­”â€ï¼šç›®æ ‡ä¸æ˜ç¡®æˆ–è¿è§„
    """
    # print(f"\n=====æˆ‘ä»¬çœ‹çœ‹è¿›å…¥åˆ°rejectçš„çŠ¶æ€æ˜¯å•¥æ ·ï¼š=====\n{state}\n")
    query = state["query"]
    messages = state["messages"]
    prompt = f"è¯·ç»¼åˆå†å²ä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­å½“å‰é—®é¢˜çš„ç›®æ ‡æ˜¯å¦æ˜ç¡®å’Œä¸è¿è§„ï¼Œå¦‚æœæ˜¯èƒ½é€šè¿‡æŸ¥è¯¢æ¡ˆä¾‹å¾—åˆ°ç­”æ¡ˆçš„ã€è¿”å›â€œå›ç­”â€ï¼Œå¦åˆ™è¿”å›â€œæ‹’ç­”â€ã€‚è¯·ä¸è¦è½»æ˜“æ‹’ç­”ï¼Œåªæœ‰åœ¨é—®é¢˜éå¸¸ä¸æ˜ç¡®ã€ä¸Šä¸‹æ–‡å®Œå…¨æ²¡ä¿¡æ¯çš„æ—¶å€™æ‰è¿”å›â€œæ‹’ç­”â€ã€‚ç”¨æˆ·å½“å‰çš„é—®é¢˜æ˜¯ï¼š{query}ã€‚"
    messages.append(
        {
            "role": "user",
            "content": prompt,
        }
    )

    response = llm.invoke(messages)
    messages.pop()  # å‰”é™¤ä¸­é—´åˆ¤æ–­ä¿¡æ¯

    # è¿‡ç¨‹è®°å½•
    state["memory"].extend(
        [
            {
                "role": "reject",
                "content": prompt,
            },
            {
                "role": "assistant",
                "content": response.content,
            },
        ]
    )
    return {"reject": response.content}


# åˆ†ææ¡ä»¶
def should_analyse(state: State):
    """
    è·¯ç”±æ¨¡å—ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†æå›ç­”
    """
    # print(f"\n=====æˆ‘ä»¬çœ‹çœ‹è¿›å…¥åˆ°should_analyseçš„çŠ¶æ€æ˜¯å•¥æ ·ï¼š=====\n{state}\n")
    # ç›®æ ‡æ˜ç¡®ä¸”ä¸è¿è§„
    print(f"\nğŸ‘‰æ˜¯å¦æ‹’ç­”ï¼š{state['reject']}")
    if "å›ç­”" in state["reject"]:
        return "å›ç­”"
    else:
        # æ‹’ç­”ç›´æ¥ç»“æŸï¼Œæ‰€ä»¥è¡¥ä¸ŠåŸå§‹æŸ¥è¯¢å’Œæ‹’ç­”è¯æœ¯
        state["messages"].extend(
            [
                {
                    "role": "user",
                    "content": state["query"],
                },
                {
                    "role": "assistant",
                    "content": "å¾ˆæŠ±æ­‰ï¼Œè¿™ä¸ªé—®é¢˜ä¸æ˜¯å®¡è®¡æ¡ˆä¾‹ç›¸å…³é—®é¢˜ï¼Œæˆ‘ä¸ä½œå›ç­”ã€‚",
                },
            ]
        )
        state["response"] = "å¾ˆæŠ±æ­‰ï¼Œè¿™ä¸ªé—®é¢˜ä¸æ˜¯å®¡è®¡æ¡ˆä¾‹ç›¸å…³é—®é¢˜ï¼Œæˆ‘ä¸ä½œå›ç­”ã€‚"

        return "æ‹’ç­”"


# è¿½é—®åˆ¤æ–­
def ask_further(state: State):
    # print(f"\n=====æˆ‘ä»¬çœ‹çœ‹è¿›å…¥åˆ°ask_furtherçš„çŠ¶æ€æ˜¯å•¥æ ·ï¼š=====\n{state}\n")
    """
    åˆ†ææ˜¯å¦æ˜¯ä¸€ä¸ªæ–°é—®é¢˜ï¼Œè¿˜æ˜¯æ—§é—®é¢˜çš„è¿½é—®ã€‚
    æ–°é—®é¢˜ï¼Œåé¢è¦èµ°æ”¹å†™+esæ£€ç´¢
    æ—§é—®é¢˜è¿½é—®ï¼Œç›´æ¥èµ°åˆ†æ
    """
    query = state["query"]
    # æ±‡æ€»æ„å›¾+æœ¯è¯­
    prompt = f"è¯·åˆ¤æ–­ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦æ˜¯è¿½é—®ã€‚å¦‚æœæ˜¯ä¸€ä¸ªæ–°é—®é¢˜ã€éœ€è¦è¿›ä¸€æ­¥ä»æ•°æ®åº“æŸ¥æ‰¾æ¡ˆä¾‹ï¼Œåˆ™ä¸æ˜¯è¿½é—®ï¼Œè¿”å›â€œå¦â€ã€‚å¦‚æœè¯¥é—®é¢˜æ˜¯å»¶ç»­ä¹‹å‰ä¸Šä¸‹æ–‡çš„è¡¥å……æé—®ï¼Œåˆ™æ˜¯è¿½é—®ï¼Œè¿”å›â€œæ˜¯â€ã€‚è¯·è°¨æ…å›ç­”â€œæ˜¯â€ï¼Œå› ä¸ºè¿½é—®å°†ä¸å†æ£€ç´¢æ¡ˆä¾‹åº“ï¼Œç›´æ¥åŸºäºä¸Šä¸‹æ–‡å›ç­”ã€‚ç”¨æˆ·æœ¬è½®çš„é—®é¢˜æ˜¯ï¼š{query}ï¼Œ"

    message = state["messages"]
    message.append(
        {
            "role": "user",
            "content": prompt,
        }
    )

    # è¿½é—®åˆ¤æ–­
    new_or_old = llm.invoke(message).content
    state["memory"].extend(
        [
            {
                "role": "ask_further",
                "content": prompt,
            },
            {
                "role": "assistant",
                "content": new_or_old,
            },
        ]
    )
    print(f"\nğŸ‘‰æ˜¯å¦è¿½é—®ï¼š{new_or_old}")

    message.pop()  # å‰”é™¤è¿‡ç¨‹äº¤äº’è®°å½•
    return {"ask_further": new_or_old}


def should_es_search(state: State):
    """
    è·¯ç”±æ¨¡å—ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ä»ESæœç´¢æ¡ˆä¾‹
    """
    # æ˜¯è¿½é—®ï¼Œæ— éœ€ä»ESæœç´¢ï¼Œç›´æ¥è¡¥ä¸ŠåŸå§‹æŸ¥è¯¢
    if "æ˜¯" in state["ask_further"]:
        # è¿½é—®çš„ï¼Œå°±åœ¨æ¶ˆæ¯ä¸­è¡¥ä¸ŠåŸå§‹æŸ¥è¯¢
        state["messages"].append(
            {
                "role": "user",
                "content": state["query"],
            }
        )
        return "æ˜¯"
    else:
        return "å¦"


# æ¨¡ç³Šè¯è¡¨
illdefined_schema = {
    "è¿‘æœŸ": "è¿‘ä¸‰ä¸ªæœˆ",
}
# ä¸“ä¸šæœ¯è¯­è¡¨
professional_schema = {
    "é”€å”®é€‚å½“æ€§": "é”€å”®é€‚å½“æ€§æ˜¯æŒ‡åœ¨é”€å”®æ´»åŠ¨ä¸­ï¼Œé”€å”®çš„ä¿é™©äº§å“æ˜¯å¦ç¬¦åˆå®¢æˆ·é£é™©éœ€æ±‚ã€‚",
}


# æŒ‡ä»¤ç†è§£
def rewrite(state: State):
    """
    1. æ„å›¾ç†è§£
    2. ä¸“ä¸šæœ¯è¯­æœç´¢
    3. æ¨¡ç³Šè¯è¯­æœç´¢
    4. æŒ‡ä»¤æ”¹å†™ï¼Œæ›´æ–°åœ¨çŠ¶æ€çš„"query_rewrite"å­—æ®µ
    """
    query = state["query"]
    # ä¸“ä¸šæœ¯è¯­æœç´¢
    professional_terms = {}
    for term in professional_schema.keys():
        if term in query:
            professional_terms.update({term: professional_schema[term]})
    # æ¨¡ç³Šè¯è¯­æœç´¢
    illdefined_terms = {}
    for term in illdefined_schema.keys():
        if term in query:
            illdefined_terms.update({term: illdefined_schema[term]})
    # æ±‡æ€»æ„å›¾+æœ¯è¯­
    prompt = f"ä½ æ˜¯ä¸€ä¸ªæŒ‡ä»¤ç†è§£æ¨¡å‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯å‚è€ƒä¸Šä¸‹æ–‡å¹¶ç»“åˆç”¨æˆ·å½“å‰çš„æŒ‡ä»¤ï¼Œå°†å…¶æ”¹å†™ä¸ºä¿¡æ¯å…¨é¢çš„æŒ‡ä»¤ï¼Œåªéœ€è¦è¾“å‡ºä½ æ”¹å†™åçš„æŒ‡ä»¤ã€‚ç”¨æˆ·çš„æŒ‡ä»¤æ˜¯ï¼š{query}ã€‚å…¶ä¸­ç›¸å…³ä¸“ä¸šæœ¯è¯­å®šä¹‰å¦‚ä¸‹ï¼š{professional_terms}ã€‚æ¨¡ç³Šè¡¨è¿°å®šä¹‰å¦‚ä¸‹ï¼š{illdefined_terms}ã€‚"

    message = state["messages"]
    message.append(
        {
            "role": "user",
            "content": prompt,
        }
    )

    # æŒ‡ä»¤æ”¹å†™
    query_rewrite = llm.invoke(message).content
    print(f"\nğŸ‘‰æŒ‡ä»¤æ”¹å†™ï¼š{query_rewrite}")
    message.pop()  # å‰”é™¤è¿‡ç¨‹äº¤äº’è®°å½•ï¼Œåç»­å°†æŸ¥è¯¢æ¡ˆä¾‹åº“å½¢æˆå®Œæ•´çš„åˆ†ææŒ‡ä»¤

    state["memory"].extend(
        [
            {
                "role": "professional_terms",
                "content": professional_terms,
            },
            {
                "role": "illdefined_terms",
                "content": illdefined_terms,
            },
            {
                "role": "query_rewrite",
                "content": query_rewrite,
            },
        ]
    )

    return {"query_rewrite": query_rewrite}


# ESæ¡ˆä¾‹æœç´¢
def es_search(state: State):
    """
    ESæ¡ˆä¾‹å–æ•°æ¨¡å—
    1. æ ¹æ®ç”¨æˆ·æƒé™åšè§„åˆ™ç­›é€‰
    2. æ ¹æ®æŸ¥è¯¢åšè¯­ä¹‰ç­›é€‰
    """
    # è·å–å›ºåŒ–çš„ä¿¡æ¯
    rt = get_runtime(Ctx)
    user_province = rt.context.get("user_province", "")
    user_city = rt.context.get("user_city", "")
    user_district = rt.context.get("user_district", "")
    user_subcompany = rt.context.get("user_subcompany", "")
    topk = rt.context.get("topk", 5)
    threshold = rt.context.get("threshold", 0.0)

    query_rewrite = state["query_rewrite"]
    query_vec = text2vec(query_rewrite)

    if (
        user_province == ""
        and user_city == ""
        and user_district == ""
        and user_subcompany == ""
    ):  # å®¡è®¡æ€»éƒ¨æƒé™
        query_es = {"match_all": {}}
    else:
        # æœºæ„æƒé™ï¼Œåªèƒ½æŸ¥çœ‹å¯¹åº”çš„æ¡ˆä¾‹
        must_clauses = [{"term": {"å­å…¬å¸": user_subcompany}}]
        if user_province != "":
            must_clauses.append({"term": {"çœ": user_province}})
        if user_city != "":
            must_clauses.append({"term": {"å¸‚": user_city}})
        if user_district != "":
            must_clauses.append({"term": {"åˆ†æ”¯æœºæ„": user_district}})
        query_es = {
            "bool": {
                "must": must_clauses,
            },
        }
    tool_config = SimpleNamespace(
        index_allowlist=None,
        request_timeout=10.0,
        max_hits_cap=200,
    )
    tool = ESVectorSearchTool(
        es=es,
        config=tool_config,
        embeddings=None,
        embedding_fn=text2vec,
    )
    result = tool._run(
        index=index_name,
        query_text=query_rewrite,
        vector_field="ç¼ºé™·å†…å®¹å‘é‡_qwen",
        k=topk,
        num_candidates=max(topk * 5, 50),
        filter=query_es,
        source_includes=["å­å…¬å¸", "çœ", "å¸‚", "åˆ†æ”¯æœºæ„", "ç¼ºé™·å†…å®¹"],
    )
    hits = result.get("hits", {}).get("hits", [])
    print(f"\nESå‘½ä¸­: {len(hits)}")
    for i, hit in enumerate(hits[: min(topk, 3)], 1):
        src = hit.get("_source", {})
        score = hit.get("_score", 0.0)
        region = f"{src.get('çœ', '')}/{src.get('å¸‚', '')}/{src.get('åˆ†æ”¯æœºæ„', '')}"
        company = src.get("å­å…¬å¸", "")
        text = src.get("ç¼ºé™·å†…å®¹", "")
        snippet = (text[:60] + "â€¦") if isinstance(text, str) and len(text) > 60 else text
        print(f"{i}. {company} {region} | {score:.3f} | {snippet}")

    # æ±‡æ€»æ¡ˆä¾‹å’Œç›¸ä¼¼åº¦å¾—åˆ†
    cases = []
    for case_info in result["hits"]["hits"]:
        case = case_info["_source"]
        score = case_info.get("_score", 0.0)
        if score > threshold:
            cases.append(case)  # å…ˆä¸è€ƒè™‘é˜ˆå€¼

    return {"cases": cases}


# æ¡ˆä¾‹åˆ†æ
def analyse(state: State):
    """
    åˆ†æå›ç­”
    """
    # print(f"\n=====æˆ‘ä»¬çœ‹çœ‹è¿›å…¥åˆ°analyseçš„çŠ¶æ€æ˜¯å•¥æ ·ï¼š=====\n{state}\n")
    messages = state["messages"]

    # è¿½é—®å°±ç”¨åŸå§‹é—®é¢˜ã€‚éè¿½é—®ç”¨é—®é¢˜æ”¹å†™å’Œcaseå†…å®¹ã€‚
    if state["ask_further"] == "æ˜¯":
        messages.append(
            {
                "role": "user",
                "content": f"è¯·æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚ç”¨æˆ·é—®é¢˜ä¸ºï¼š{state['query']}ã€‚",
            }
        )
    else:
        messages.append(
            {
                "role": "user",
                "content": f"è¯·æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç»“åˆç›¸å…³æ¡ˆä¾‹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚ç›¸å…³æ¡ˆä¾‹ä¸ºï¼š{state['cases']}ï¼Œç”¨æˆ·é—®é¢˜ä¸ºï¼š{state['query_rewrite']}",
            }
        )

    response = llm.invoke(messages)
    messages.append(
        {
            "role": "assistant",
            "content": response.content,
        }
    )

    state["memory"].extend(
        [
            {
                "role": "analyse",
                "content": messages[-1]["content"],
            },
        ]
    )

    return {"response": messages[-1]["content"]}


# å»ºç«‹é™æ€å›¾
graph = StateGraph(State)
graph.add_node("æ‹’ç­”åˆ¤æ–­", reject)
graph.add_node("è¿½é—®åˆ¤æ–­", ask_further)
graph.add_node("æŒ‡ä»¤æ”¹å†™", rewrite)
graph.add_node("æ¡ˆä¾‹æ£€ç´¢", es_search)
graph.add_node("åˆ†æå›ç­”", analyse)
graph.add_edge(START, "æ‹’ç­”åˆ¤æ–­")
graph.add_conditional_edges(
    "æ‹’ç­”åˆ¤æ–­", should_analyse, {"æ‹’ç­”": END, "å›ç­”": "è¿½é—®åˆ¤æ–­"}
)
graph.add_conditional_edges(
    "è¿½é—®åˆ¤æ–­", should_es_search, {"æ˜¯": "åˆ†æå›ç­”", "å¦": "æŒ‡ä»¤æ”¹å†™"}
)
graph.add_edge("æŒ‡ä»¤æ”¹å†™", "æ¡ˆä¾‹æ£€ç´¢")
graph.add_edge("æ¡ˆä¾‹æ£€ç´¢", "åˆ†æå›ç­”")
graph.add_edge("åˆ†æå›ç­”", END)

# ç¼–è¯‘é™æ€å›¾
app = graph.compile()

# ç²—ç•¥å¯è§†åŒ–
app.get_graph().print_ascii()


if __name__ == "__main__":
    """
    è¯·å¸®æˆ‘æŸ¥ä¸€ä¸‹å†œé™©è¿‘æœŸç¼ºé™·æ¡ˆä¾‹æœ‰å“ªäº›ï¼Ÿ
    è¿™äº›æ¡ˆä¾‹éƒ½æ˜¯å“ªä¸ªçœçš„ï¼Ÿ
    """
    # å›ºè¯agentçŠ¶æ€ï¼Œä¹Ÿå¯ç”¨äºåç»­ä¿å­˜å’Œè½½å…¥
    state = {
        "messages": [],
        "memory": [],
        "query": "",
        "reject": "",
        "query_rewrite": "",
        "response": "",
    }
    context = {
        "user_province": "å±±ä¸œçœ",
        "user_city": "",
        "user_district": "",
        "user_subcompany": "äº§é™©",
        "topk": 3,
        "threshold": 0.0,
    }

    print("\nğŸ¤– æœºå™¨äººï¼šä½ å¥½å‘€ï¼")

    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nğŸ‘¤ ä½ : ")

        # å¦‚æœè¾“å…¥ exit å°±ç»“æŸ
        if user_input.lower() == "exit":
            print("\nğŸ¤– æœºå™¨äºº: å†è§ï¼")
            break

        # æ›´æ–°agentçŠ¶æ€ï¼Œæ›¿æ¢ä¸ºæœ¬è½®ç”¨æˆ·æŸ¥è¯¢
        state["query"] = user_input
        # print(state)
        state = app.invoke(state, context=context)
        print(f"\nğŸ¤– æœºå™¨äººï¼š{state.get('response', 'æœ¬è½®æ‹’ç­”')}")
        # print(f"\n=====æˆ‘ä»¬çœ‹çœ‹ç»“æŸçš„çŠ¶æ€æ˜¯å•¥æ ·ï¼š=====\n{state}\n")




